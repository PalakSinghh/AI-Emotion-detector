{"cells":[{"cell_type":"markdown","metadata":{"id":"dVTymJearEJn"},"source":[" IMPORT LIBRARIES AND DATASETS"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20950,"status":"ok","timestamp":1682979156592,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"oXQvU_ijrFp8","outputId":"d431febc-c113-46ee-804a-6a747fdc9b92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":777,"status":"ok","timestamp":1682979157364,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"gkdq6xgwrHD8","outputId":"edd5d098-f21c-4d4d-ec03-7d35b7dfa2de"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Emotion AI /'\n","/content\n"]}],"source":["%cd /content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Emotion AI /\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3983,"status":"ok","timestamp":1682979161345,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"vQFbssqfr_UL"},"outputs":[],"source":["# Import the necessary packages\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import PIL\n","import seaborn as sns\n","import pickle\n","from PIL import *\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from IPython.display import display\n","from tensorflow.python.keras import *\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, optimizers\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import *\n","from tensorflow.keras import backend as K\n","from keras import optimizers\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"elapsed":85,"status":"error","timestamp":1682979161361,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"klj2F-OQr_Wn","outputId":"63efa36f-8764-4712-8e29-64af6a90c8e4"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-fb5129c9bac7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load facial key points data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkeyfacial_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Emotion AI /data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Emotion AI /data.csv'"]}],"source":["# load facial key points data\n","keyfacial_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Emotion AI /data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":84,"status":"aborted","timestamp":1682979161364,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"xTb3fLL8r_ZQ"},"outputs":[],"source":["keyfacial_df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":88,"status":"aborted","timestamp":1682979161368,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"9yFsN8SAtHum"},"outputs":[],"source":["# Obtain relavant information about the dataframe\n","keyfacial_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":91,"status":"aborted","timestamp":1682979161372,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"AJhdlYRqtKVK"},"outputs":[],"source":["# Check if null values exist in the dataframe\n","keyfacial_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":94,"status":"aborted","timestamp":1682979161376,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"u-s17cxKBvd3"},"outputs":[],"source":["keyfacial_df['Image'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":98,"status":"aborted","timestamp":1682979161381,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"qtGMT3ozr_g3"},"outputs":[],"source":["# Since values for the image are given as space separated string, separate the values using ' ' as separator.\n","# Then convert this into numpy array using np.fromstring and convert the obtained 1D array into 2D array of shape (96, 96)\n","keyfacial_df['Image'] = keyfacial_df['Image'].apply(lambda x: np.fromstring(x, dtype = int, sep = ' ').reshape(96, 96))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":98,"status":"aborted","timestamp":1682979161382,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"KE1RIIy8r_fN"},"outputs":[],"source":["# Obtain the Shape of the image\n","keyfacial_df['Image'][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":102,"status":"aborted","timestamp":1682979161386,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"06r0LqnKflxU"},"outputs":[],"source":["keyfacial_df.describe()"]},{"cell_type":"markdown","metadata":{"id":"bNkYttG_tOKf"},"source":["PERFORM IMAGE VISUALIZATION"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":102,"status":"aborted","timestamp":1682979161387,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"KpJujwjyr_dc"},"outputs":[],"source":["# Plot a random image from the dataset along with facial keypoints. \n","# Image data is obtained from df['Image'] and plotted using plt.imshow\n","# 15 x and y coordinates for the corresponding image \n","# since x-coordinates are in even columns like 0,2,4,.. and y-coordinates are in odd columns like 1,3,5,..\n","# we access their value using .loc command, which get the values for coordinates of the image based on the column it is refering to.\n","\n","i = np.random.randint(1, len(keyfacial_df))\n","plt.imshow(keyfacial_df['Image'][i], cmap = 'gray')\n","for j in range(1, 31, 2):\n","        plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":104,"status":"aborted","timestamp":1682979161389,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"oSZfQwc3r_be"},"outputs":[],"source":["# Let's view more images in a grid format\n","fig = plt.figure(figsize=(20, 20))\n","\n","for i in range(16):\n","    ax = fig.add_subplot(4, 4, i + 1)    \n","    image = plt.imshow(keyfacial_df['Image'][i],cmap = 'gray')\n","    for j in range(1,31,2):\n","        plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":105,"status":"aborted","timestamp":1682979161391,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"tPbtjUqHhYTX"},"outputs":[],"source":["import random\n","# Let's view more images in a grid format\n","fig = plt.figure(figsize=(20, 20))\n","\n","for i in range(64):\n","    k = random.randint(1, len(keyfacial_df))\n","    ax = fig.add_subplot(8, 8, i + 1)    \n","    image = plt.imshow(keyfacial_df['Image'][k],cmap = 'gray')\n","    for j in range(1,31,2):\n","        plt.plot(keyfacial_df.loc[k][j-1], keyfacial_df.loc[k][j], 'rx')\n","    "]},{"cell_type":"markdown","metadata":{"id":"wbqDwd1mteJ4"},"source":[" PERFORM IMAGE AUGMENTATION"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":105,"status":"aborted","timestamp":1682979161392,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"H3TLq1UbtazX"},"outputs":[],"source":["# Create a new copy of the dataframe\n","import copy\n","keyfacial_df_copy = copy.copy(keyfacial_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":110,"status":"aborted","timestamp":1682979161399,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"ypyn10X7tbrb"},"outputs":[],"source":["# Obtain the columns in the dataframe\n","\n","columns = keyfacial_df_copy.columns[:-1]\n","columns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26342,"status":"aborted","timestamp":1682979161401,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"hyFb3o1ztbyr"},"outputs":[],"source":["# Horizontal Flip - flip the images along y axis\n","keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x: np.flip(x, axis = 1))\n","\n","# since we are flipping horizontally, y coordinate values would be the same\n","# Only x coordiante values would change, all we have to do is to subtract our initial x-coordinate values from width of the image(96)\n","for i in range(len(columns)):\n","  if i%2 == 0:\n","    keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26336,"status":"aborted","timestamp":1682979161402,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"fIM1786rtb37"},"outputs":[],"source":["# Show the Original image\n","plt.imshow(keyfacial_df['Image'][0], cmap = 'gray')\n","for j in range(1, 31, 2):\n","        plt.plot(keyfacial_df.loc[0][j-1], keyfacial_df.loc[0][j], 'rx')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26331,"status":"aborted","timestamp":1682979161404,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"1kVUp-UMtbwg"},"outputs":[],"source":["# Show the Horizontally flipped image\n","plt.imshow(keyfacial_df_copy['Image'][0],cmap='gray')\n","for j in range(1, 31, 2):\n","        plt.plot(keyfacial_df_copy.loc[0][j-1], keyfacial_df_copy.loc[0][j], 'rx')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26330,"status":"aborted","timestamp":1682979161405,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"-g67tKjwtbua"},"outputs":[],"source":["# Concatenate the original dataframe with the augmented dataframe\n","augmented_df = np.concatenate((keyfacial_df, keyfacial_df_copy))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26325,"status":"aborted","timestamp":1682979161405,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"IRag8bteDzVl"},"outputs":[],"source":["augmented_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26319,"status":"aborted","timestamp":1682979161406,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"COzWKpthtvRW"},"outputs":[],"source":["# Randomingly increasing the brightness of the images\n","# We multiply pixel values by random values between 1.5 and 2 to increase the brightness of the image\n","# we clip the value between 0 and 255\n","\n","import random\n","\n","keyfacial_df_copy = copy.copy(keyfacial_df)\n","keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x:np.clip(random.uniform(1.5, 2)* x, 0.0, 255.0))\n","augmented_df = np.concatenate((augmented_df, keyfacial_df_copy))\n","augmented_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26312,"status":"aborted","timestamp":1682979161407,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"S_Pvd2qqtvkF"},"outputs":[],"source":["# Show Image with increased brightness\n","\n","plt.imshow(keyfacial_df_copy['Image'][0], cmap='gray')\n","for j in range(1, 31, 2):\n","        plt.plot(keyfacial_df_copy.loc[0][j-1], keyfacial_df_copy.loc[0][j], 'rx')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26310,"status":"aborted","timestamp":1682979161407,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"iQV4Lwr6dkmK"},"outputs":[],"source":["keyfacial_df_copy = copy.copy(keyfacial_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26310,"status":"aborted","timestamp":1682979161408,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"X607yQkqCBd9"},"outputs":[],"source":["keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x: np.flip(x, axis = 0))\n","\n","for i in range(len(columns)):\n","  if i%2 == 1:\n","    keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26304,"status":"aborted","timestamp":1682979161409,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"ERhDcD2XiP4u"},"outputs":[],"source":["plt.imshow(keyfacial_df_copy['Image'][0], cmap='gray')\n","for j in range(1, 31, 2):\n","        plt.plot(keyfacial_df_copy.loc[0][j-1], keyfacial_df_copy.loc[0][j], 'rx')"]},{"cell_type":"markdown","metadata":{"id":"tz56c0e0t71Y"},"source":[" PERFORM DATA NORMALIZATION AND TRAINING DATA PREPARATION"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26301,"status":"aborted","timestamp":1682979161412,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"sNdOOb0Ctvei"},"outputs":[],"source":["# Obtain the value of images which is present in the 31st column (since index start from 0, we refer to 31st column by 30)\n","img = augmented_df[:,30]\n","\n","# Normalize the images\n","img = img/255.\n","\n","# Create an empty array of shape (x, 96, 96, 1) to feed the model\n","X = np.empty((len(img), 96, 96, 1))\n","\n","# Iterate through the img list and add image values to the empty array after expanding it's dimension from (96, 96) to (96, 96, 1)\n","for i in range(len(img)):\n","  X[i,] = np.expand_dims(img[i], axis = 2)\n","\n","# Convert the array type to float32\n","X = np.asarray(X).astype(np.float32)\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26296,"status":"aborted","timestamp":1682979161413,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"hPNN-RKftvcF"},"outputs":[],"source":["# Obtain the value of x & y coordinates which are to used as target.\n","y = augmented_df[:,:30]\n","y = np.asarray(y).astype(np.float32)\n","y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":51,"status":"aborted","timestamp":1682979162145,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"cl7FHUUMtvZr"},"outputs":[],"source":["# Split the data into train and test data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162146,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"rQmZG5fxkU9d"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":51,"status":"aborted","timestamp":1682979162146,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"xe_63C3PFiIC"},"outputs":[],"source":["X_test.shape"]},{"cell_type":"markdown","metadata":{"id":"yIXkiaHBuNrg"},"source":[" BUILD DEEP RESIDUAL NEURAL NETWORK KEY FACIAL POINTS DETECTION MODEL "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162147,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"7lCAPjVotvXi"},"outputs":[],"source":["def res_block(X, filter, stage):\n","\n","  # Convolutional_block\n","  X_copy = X\n","\n","  f1 , f2, f3 = filter\n","\n","  # Main Path\n","  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = MaxPool2D((2,2))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n","\n","\n","  # Short path\n","  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n","  X_copy = MaxPool2D((2,2))(X_copy)\n","  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n","\n","  # ADD\n","  X = Add()([X,X_copy])\n","  X = Activation('relu')(X)\n","\n","  # Identity Block 1\n","  X_copy = X\n","\n","\n","  # Main Path\n","  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n","\n","  # ADD\n","  X = Add()([X,X_copy])\n","  X = Activation('relu')(X)\n","\n","  # Identity Block 2\n","  X_copy = X\n","\n","\n","  # Main Path\n","  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n","\n","  # ADD\n","  X = Add()([X,X_copy])\n","  X = Activation('relu')(X)\n","\n","  return X"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162148,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"NB9dPqlTtvVH"},"outputs":[],"source":["input_shape = (96, 96, 1)\n","\n","# Input tensor shape\n","X_input = Input(input_shape)\n","\n","# Zero-padding\n","X = ZeroPadding2D((3,3))(X_input)\n","\n","# 1 - stage\n","X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n","X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n","X = Activation('relu')(X)\n","X = MaxPooling2D((3,3), strides= (2,2))(X)\n","\n","# 2 - stage\n","X = res_block(X, filter= [64,64,256], stage= 2)\n","\n","# 3 - stage\n","X = res_block(X, filter= [128,128,512], stage= 3)\n","\n","\n","# Average Pooling\n","X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n","\n","# Final layer\n","X = Flatten()(X)\n","X = Dense(4096, activation = 'relu')(X)\n","X = Dropout(0.2)(X)\n","X = Dense(2048, activation = 'relu')(X)\n","X = Dropout(0.1)(X)\n","X = Dense(30, activation = 'relu')(X)\n","\n","\n","model_1_facialKeyPoints = Model( inputs= X_input, outputs = X)\n","model_1_facialKeyPoints.summary()"]},{"cell_type":"markdown","metadata":{"id":"IJCLhas0ulnq"},"source":[" COMPILE AND TRAIN KEY FACIAL POINTS DETECTION DEEP LEARNING MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162149,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"mr662N98upOP"},"outputs":[],"source":["adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n","model_1_facialKeyPoints.compile(loss = \"mean_squared_error\", optimizer = adam , metrics = ['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162149,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"2pj-gfDCusny"},"outputs":[],"source":["# save the best model with least validation loss\n","checkpointer = ModelCheckpoint(filepath = \"FacialKeyPoints_weights.hdf5\", verbose = 1, save_best_only = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162150,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"2VLk1ZKPusjM"},"outputs":[],"source":["# save the model architecture to json file for future use\n","\n","model_json = model_1_facialKeyPoints.to_json()\n","with open(\"FacialKeyPoints-model.json\",\"w\") as json_file:\n","  json_file.write(model_json)\n"]},{"cell_type":"markdown","metadata":{"id":"c-cVW8K62Pai"},"source":[" ASSESS TRAINED KEY FACIAL POINTS DETECTION MODEL PERFORMANCE"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162150,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"-iGWmYbdu2mF"},"outputs":[],"source":["with open('detection.json', 'r') as json_file:\n","    json_savedModel= json_file.read()\n","    \n","# load the model architecture \n","model_1_facialKeyPoints = tf.keras.models.model_from_json(json_savedModel)\n","model_1_facialKeyPoints.load_weights('weights_keypoint.hdf5')\n","adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model_1_facialKeyPoints.compile(loss=\"mean_squared_error\", optimizer= adam , metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162150,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"-XuTiBexu2j5"},"outputs":[],"source":["# Evaluate the model\n","\n","result = model_1_facialKeyPoints.evaluate(X_test, y_test)\n","print(\"Accuracy : {}\".format(result[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1682979162151,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"TJfpDL2xu2cV"},"outputs":[],"source":["# Plot the training artifacts\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train_loss','val_loss'], loc = 'upper right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HvTWqbOI2tty"},"source":["# PART 2. FACIAL EXPRESSION DETECTION"]},{"cell_type":"markdown","metadata":{"id":"wIKg0ZXk3DWl"},"source":[" IMPORT & EXPLORE DATASET FOR FACIAL EXPRESSION DETECTION"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1682979162151,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"u_NT8ASSu2aT"},"outputs":[],"source":["# read the csv files for the facial expression data\n","facialexpression_df = pd.read_csv('icml_face_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46,"status":"aborted","timestamp":1682979162151,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"CTiebNB2u2YP"},"outputs":[],"source":["facialexpression_df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":45,"status":"aborted","timestamp":1682979162151,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"yGIesU_F0AMm"},"outputs":[],"source":["facialexpression_df[' pixels'][0] # String format"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":45,"status":"aborted","timestamp":1682979162152,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"MMLQbIEh3Ma6"},"outputs":[],"source":["# function to convert pixel values in string format to array format\n","\n","def string2array(x):\n","  return np.array(x.split(' ')).reshape(48, 48, 1).astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1682979162152,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"RkUHXFoU3MYq"},"outputs":[],"source":["# Resize images from (48, 48) to (96, 96)\n","\n","def resize(x):\n","  \n","  img = x.reshape(48, 48)\n","  return cv2.resize(img, dsize=(96, 96), interpolation = cv2.INTER_CUBIC)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1682979162153,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"GexILbbK3MWK"},"outputs":[],"source":["facialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: string2array(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1682979162153,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"RZr0wp553MUp"},"outputs":[],"source":["facialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: resize(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1682979162153,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"2Rbv7ZyC3MSM"},"outputs":[],"source":["facialexpression_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1682979162154,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"gkreBNCT3MPu"},"outputs":[],"source":["# check the shape of data_frame\n","facialexpression_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1682979162155,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"gkQQp5gy3MNa"},"outputs":[],"source":["# check for the presence of null values in the data frame\n","facialexpression_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1682979162157,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"G-BzW6jL3MK0"},"outputs":[],"source":["label_to_text = {0:'anger', 1:'disgust', 2:'sad', 3:'happiness', 4: 'surprise'}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1682979162157,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"_xm9oL5k1ED6"},"outputs":[],"source":["plt.imshow(facialexpression_df[' pixels'][0], cmap = 'gray')"]},{"cell_type":"markdown","metadata":{"id":"5JtBq4Ys3m5A"},"source":["VISUALIZE IMAGES AND PLOT LABELS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":43,"status":"aborted","timestamp":1682979162158,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"tZmIbWvE3rJM"},"outputs":[],"source":["emotions = [0, 1, 2, 3, 4]\n","\n","for i in emotions:\n","  data = facialexpression_df[facialexpression_df['emotion'] == i][:1]\n","  img = data[' pixels'].item()\n","  img = img.reshape(96, 96)\n","  plt.figure()\n","  plt.title(label_to_text[i])\n","  plt.imshow(img, cmap = 'gray')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":43,"status":"aborted","timestamp":1682979162158,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"Mqd57PASp_tl"},"outputs":[],"source":["facialexpression_df.emotion.value_counts().index"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":43,"status":"aborted","timestamp":1682979162158,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"bMnwhXw_qGyq"},"outputs":[],"source":["facialexpression_df.emotion.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":44,"status":"aborted","timestamp":1682979162159,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"oxAbaC1g3pNP"},"outputs":[],"source":["plt.figure(figsize = (10,10))\n","sns.barplot(x = facialexpression_df.emotion.value_counts().index, y = facialexpression_df.emotion.value_counts())"]},{"cell_type":"markdown","metadata":{"id":"Ib_YTklF3wGy"},"source":["PERFORM DATA PREPARATION AND IMAGE AUGMENTATION"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39,"status":"aborted","timestamp":1682979162160,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"HgzxfltG3rHt"},"outputs":[],"source":["# split the dataframe in to features and labels\n","from keras.utils import to_categorical\n","\n","X = facialexpression_df[' pixels']\n","y = to_categorical(facialexpression_df['emotion'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":38,"status":"aborted","timestamp":1682979162160,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"gx91bryj0zu_"},"outputs":[],"source":["X[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39,"status":"aborted","timestamp":1682979162161,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"WNDkM9ZL0-kP"},"outputs":[],"source":["y"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1682979162162,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"pfPslLye0wgZ"},"outputs":[],"source":["\n","X = np.stack(X, axis = 0)\n","X = X.reshape(24568, 96, 96, 1)\n","\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39,"status":"aborted","timestamp":1682979162162,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"Q1zcH-d83rGF"},"outputs":[],"source":["# split the dataframe in to train, test and validation data frames\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_Test, y_train, y_Test = train_test_split(X, y, test_size = 0.1, shuffle = True)\n","X_val, X_Test, y_val, y_Test = train_test_split(X_Test, y_Test, test_size = 0.5, shuffle = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1682979162163,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"kkLQt43f3rE2"},"outputs":[],"source":["print(X_val.shape, y_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39,"status":"aborted","timestamp":1682979162163,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"Febj9BnO1xaA"},"outputs":[],"source":["print(X_Test.shape, y_Test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1682979162164,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"YDH4-6h211dj"},"outputs":[],"source":["print(X_train.shape, y_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1682979162165,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"jDAFSti14MUD"},"outputs":[],"source":["# image pre-processing\n","\n","X_train = X_train/255\n","X_val   = X_val /255\n","X_Test  = X_Test/255"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1682979162165,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"Wh8hASOZ1_GG"},"outputs":[],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1682979162166,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"_IgiiGW64MRm"},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","rotation_range = 15,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    shear_range = 0.1,\n","    zoom_range = 0.1,\n","    horizontal_flip = True,\n","    fill_mode = \"nearest\")\n"]},{"cell_type":"markdown","metadata":{"id":"t5yyM1UF4Xv2"},"source":["BUILD AND TRAIN DEEP LEARNING MODEL FOR FACIAL EXPRESSION CLASSIFICATION"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":43,"status":"aborted","timestamp":1682979162167,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"5iYII6C24MQD"},"outputs":[],"source":["input_shape = (96, 96, 1)\n","\n","# Input tensor shape\n","X_input = Input(input_shape)\n","\n","# Zero-padding\n","X = ZeroPadding2D((3, 3))(X_input)\n","\n","# 1 - stage\n","X = Conv2D(64, (7, 7), strides= (2, 2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n","X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n","X = Activation('relu')(X)\n","X = MaxPooling2D((3, 3), strides= (2, 2))(X)\n","\n","# 2 - stage\n","X = res_block(X, filter= [64, 64, 256], stage= 2)\n","\n","# 3 - stage\n","X = res_block(X, filter= [128, 128, 512], stage= 3)\n","\n","# 4 - stage\n","# X = res_block(X, filter= [256, 256, 1024], stage= 4)\n","\n","# Average Pooling\n","X = AveragePooling2D((4, 4), name = 'Averagea_Pooling')(X)\n","\n","# Final layer\n","X = Flatten()(X)\n","X = Dense(5, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n","\n","model_2_emotion = Model( inputs= X_input, outputs = X, name = 'Resnet18')\n","\n","model_2_emotion.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":44,"status":"aborted","timestamp":1682979162168,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"4SHnD2aX4MLJ"},"outputs":[],"source":["# train the network\n","model_2_emotion.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46,"status":"aborted","timestamp":1682979162170,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"0ubSY9CQ4MJG"},"outputs":[],"source":["# Recall that the first facial key points model was saved as follows: FacialKeyPoints_weights.hdf5 and FacialKeyPoints-model.json\n","\n","# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n","earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n","\n","# save the best model with lower validation loss\n","checkpointer = ModelCheckpoint(filepath = \"FacialExpression_weights.hdf5\", verbose = 1, save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1682979162171,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"iqjpKgHK3q_n"},"outputs":[],"source":["history = model_2_emotion.fit(train_datagen.flow(X_train, y_train, batch_size=64),\n","\tvalidation_data=(X_val, y_val), steps_per_epoch=len(X_train) // 64,\n","\tepochs= 20)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1682979162172,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"oJe9up3A4zUI"},"outputs":[],"source":["# saving the model architecture to json file for future use\n","\n","model_json = model_2_emotion.to_json()\n","with open(\"FacialExpression-model.json\",\"w\") as json_file:\n","  json_file.write(model_json)"]},{"cell_type":"markdown","metadata":{"id":"0LxpMt2h5AIi"},"source":[" ASSESS THE PERFORMANCE OF TRAINED FACIAL EXPRESSION CLASSIFIER MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1682979162172,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"QKtc94LP4zSj"},"outputs":[],"source":["with open('emotion.json', 'r') as json_file:\n","    json_savedModel= json_file.read()\n","    \n","# load the model architecture \n","model_2_emotion = tf.keras.models.model_from_json(json_savedModel)\n","model_2_emotion.load_weights('weights_emotions.hdf5')\n","model_2_emotion.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1682979162173,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"NJoYkZWw43zv"},"outputs":[],"source":["score = model_2_emotion.evaluate(X_Test, y_Test)\n","print('Test Accuracy: {}'.format(score[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":49,"status":"aborted","timestamp":1682979162174,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"M27CZcLm4zQk"},"outputs":[],"source":["history.history.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":50,"status":"aborted","timestamp":1682979162175,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"a2WZ3__e5Kxp"},"outputs":[],"source":["accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":50,"status":"aborted","timestamp":1682979162175,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"sEO2vCRh5Kpz"},"outputs":[],"source":["epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":51,"status":"aborted","timestamp":1682979162176,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"k9WS5-Bv5KoD"},"outputs":[],"source":["plt.plot(epochs, loss, 'ro', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and Validation loss')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162177,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"Oduf0Q8n5Kl-"},"outputs":[],"source":["# predicted_classes = model.predict_classes(X_test)\n","predicted_classes = np.argmax(model_2_emotion.predict(X_Test), axis=-1)\n","y_true = np.argmax(y_Test, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162177,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"E5Yp58fm5Kkj"},"outputs":[],"source":["y_true.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":51,"status":"aborted","timestamp":1682979162177,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"cLdhjhBb5KeD"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_true, predicted_classes)\n","plt.figure(figsize = (10, 10))\n","sns.heatmap(cm, annot = True, cbar = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162178,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"YuLsavNIGQqA"},"outputs":[],"source":["L = 5\n","W = 5\n","\n","fig, axes = plt.subplots(L, W, figsize = (24, 24))\n","axes = axes.ravel()\n","\n","for i in np.arange(0, L*W):\n","    axes[i].imshow(X_test[i].reshape(96,96), cmap = 'gray')\n","    axes[i].set_title('Prediction = {}\\n True = {}'.format(label_to_text[predicted_classes[i]], label_to_text[y_true[i]]))\n","    axes[i].axis('off')\n","\n","plt.subplots_adjust(wspace = 1)   "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1682979162178,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"2yT4LdSCGuDJ"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_true, predicted_classes))"]},{"cell_type":"markdown","metadata":{"id":"c_Gm-Vap7Wv0"},"source":["# PART 3. COMBINE BOTH FACIAL EXPRESSION AND KEY POINTS DETECTION MODELS"]},{"cell_type":"markdown","metadata":{"id":"E_kdiO4o7IPc"},"source":["COMBINE BOTH MODELS (1) FACIAL KEY POINTS DETECTION AND (2) FACIAL EXPRESSION MODELS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162179,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"lDVsSChW7Vpi"},"outputs":[],"source":["def predict(X_test):\n","\n","  # Making prediction from the keypoint model\n","  df_predict = model_1_facialKeyPoints.predict(X_test)\n","\n","  # Making prediction from the emotion model\n","  df_emotion = np.argmax(model_2_emotion.predict(X_test), axis=-1)\n","\n","  # Reshaping array from (856,) to (856,1)\n","  df_emotion = np.expand_dims(df_emotion, axis = 1)\n","\n","  # Converting the predictions into a dataframe\n","  df_predict = pd.DataFrame(df_predict, columns= columns)\n","\n","  # Adding emotion into the predicted dataframe\n","  df_predict['emotion'] = df_emotion\n","\n","  return df_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162179,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"ULEWfmhK7vVf"},"outputs":[],"source":["df_predict = predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1682979162179,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"9g1M3Hrq7vO-"},"outputs":[],"source":["df_predict.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":54,"status":"aborted","timestamp":1682979162180,"user":{"displayName":"Palak Singh","userId":"02837240979167878107"},"user_tz":-330},"id":"7Ogvh7t-JhhM"},"outputs":[],"source":["# Plotting the test images and their predicted keypoints and emotions\n","\n","fig, axes = plt.subplots(4, 4, figsize = (24, 24))\n","axes = axes.ravel()\n","\n","for i in range(16):\n","\n","    axes[i].imshow(X_test[i].squeeze(),cmap='gray')\n","    axes[i].set_title('Prediction = {}'.format(label_to_text[df_predict['emotion'][i]]))\n","    axes[i].axis('off')\n","    for j in range(1,31,2):\n","            axes[i].plot(df_predict.loc[i][j-1], df_predict.loc[i][j], 'rx')\n","            "]}],"metadata":{"colab":{"provenance":[{"file_id":"1qPmN5jrJCMC7SXHJRzcBNcLCGZtrwV43","timestamp":1682968993005}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
